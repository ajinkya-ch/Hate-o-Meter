{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'maindatahnh.csv'\n",
    "df = pd.read_csv(path,encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>data</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noHate</td>\n",
       "      <td>12834217_1</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>As of March 13th , 2014 , the booklet had been...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noHate</td>\n",
       "      <td>12834217_10</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you in advance. : ) Download the youtube...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noHate</td>\n",
       "      <td>12834217_2</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>In order to help increase the booklets downloa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noHate</td>\n",
       "      <td>12834217_3</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>( Simply copy and paste the following text int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate</td>\n",
       "      <td>12834217_4</td>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>Click below for a FREE download of a colorfull...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label      file_id  user_id  subforum_id  num_contexts  \\\n",
       "0  noHate   12834217_1   572066         1346             0   \n",
       "1  noHate  12834217_10   572066         1346             0   \n",
       "2  noHate   12834217_2   572066         1346             0   \n",
       "3  noHate   12834217_3   572066         1346             0   \n",
       "4    hate   12834217_4   572066         1346             0   \n",
       "\n",
       "                                                data Unnamed: 6 Unnamed: 7  \n",
       "0  As of March 13th , 2014 , the booklet had been...        NaN        NaN  \n",
       "1  Thank you in advance. : ) Download the youtube...        NaN        NaN  \n",
       "2  In order to help increase the booklets downloa...        NaN        NaN  \n",
       "3  ( Simply copy and paste the following text int...        NaN        NaN  \n",
       "4  Click below for a FREE download of a colorfull...        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the meanings of the column values, per the original authors:\n",
    "\n",
    "`count` = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "\n",
    "`hate_speech` = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "`offensive_language` = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "`neither` = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "`class` = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n",
    "\n",
    "`tweet` = the actual text of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many of each class we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8415279442cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution of Speech in Dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Don't print \"class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Hate speech'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Offensive language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Neither'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mcountplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3256\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3258\u001b[0;31m                           errcolor)\n\u001b[0m\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0;32m-> 1543\u001b[0;31m                                  order, hue_order, units)\n\u001b[0m\u001b[1;32m   1544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret input 'class'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a83acf7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.countplot(x=\"class\", data=df)\n",
    "plt.title('Distribution of Speech in Dataset')\n",
    "plt.xlabel('') # Don't print \"class\"\n",
    "plt.xticks(np.arange(3), ['Hate speech', 'Offensive language', 'Neither'])\n",
    "\n",
    "# Print the number above each bar\n",
    "for p in ax.patches:\n",
    "    x = p.get_bbox().get_points()[:, 0]\n",
    "    y = int(p.get_bbox().get_points()[1, 1])\n",
    "    ax.annotate(y, (x.mean(), y), \n",
    "            ha='center', va='bottom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the unusual distribution of types of text. Because all of the tweets were pulled from HateBase, hate speech and offensive language is going to be significantly over-represented, as we see above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much agreement there was. We'll check if any were called hate speech by at least one person and neither by at least one other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@saraelizabethj4 that's what happens when you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>@RonanFarrow Yeah we know about Anglo-American...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@iamkrause \\nI ain't never orderin from no col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Maybe @barackobama is colored blind with his '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@ImASpiderG you a bitch nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@yawlknow @HoskinsTy96 \"all of these rednecks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@JamesdaJewison &amp;lt;&amp;lt;BEST NAME ON TWITTER E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22618</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This target is ghetto, but whatever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8029</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Aren't these little border jumpers supposed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21963</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The Perfect Gift for the Jihadi on Your Shoppi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12156</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Is dare any colored players in hockey?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21117</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeing elder queer couples marry really is emo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@THEHermanCain then send this one to your teab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Perhaps Ezra Miller is the first crack toward ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16113</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @JamesOKeefeIII: Denver TV airs clip of dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21974</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The Wayans bros is the most retarded show ever.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13778</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Not just exist, but contribute. And contribute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19789</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @jgalt666: Don't let a crisis go to waste.D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23387</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Why won't we run the ball? Our offensive coord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24600</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>it means that im following orders and being su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "7164       3            2                   0        1      0   \n",
       "4702       6            1                   1        4      2   \n",
       "6319       3            1                   0        2      2   \n",
       "13098      6            1                   0        5      2   \n",
       "3576       6            1                   4        1      1   \n",
       "7562       3            2                   0        1      0   \n",
       "3700       3            1                   0        2      2   \n",
       "22618      3            1                   0        2      2   \n",
       "8029       3            1                   0        2      2   \n",
       "21963      3            1                   0        2      2   \n",
       "12156      3            1                   0        2      2   \n",
       "21117      6            2                   3        1      1   \n",
       "4961       3            1                   0        2      2   \n",
       "14147      6            1                   2        3      2   \n",
       "16113      6            2                   0        4      2   \n",
       "21974      3            1                   0        2      2   \n",
       "13778      6            1                   3        2      1   \n",
       "19789      3            1                   0        2      2   \n",
       "23387      3            1                   0        2      2   \n",
       "24600      3            2                   0        1      0   \n",
       "\n",
       "                                                   tweet  \n",
       "7164   @saraelizabethj4 that's what happens when you ...  \n",
       "4702   @RonanFarrow Yeah we know about Anglo-American...  \n",
       "6319   @iamkrause \\nI ain't never orderin from no col...  \n",
       "13098  Maybe @barackobama is colored blind with his '...  \n",
       "3576                       @ImASpiderG you a bitch nigga  \n",
       "7562   @yawlknow @HoskinsTy96 \"all of these rednecks ...  \n",
       "3700   @JamesdaJewison &lt;&lt;BEST NAME ON TWITTER E...  \n",
       "22618                This target is ghetto, but whatever  \n",
       "8029   Aren't these little border jumpers supposed to...  \n",
       "21963  The Perfect Gift for the Jihadi on Your Shoppi...  \n",
       "12156             Is dare any colored players in hockey?  \n",
       "21117  Seeing elder queer couples marry really is emo...  \n",
       "4961   @THEHermanCain then send this one to your teab...  \n",
       "14147  Perhaps Ezra Miller is the first crack toward ...  \n",
       "16113  RT @JamesOKeefeIII: Denver TV airs clip of dig...  \n",
       "21974    The Wayans bros is the most retarded show ever.  \n",
       "13778  Not just exist, but contribute. And contribute...  \n",
       "19789  RT @jgalt666: Don't let a crisis go to waste.D...  \n",
       "23387  Why won't we run the ball? Our offensive coord...  \n",
       "24600  it means that im following orders and being su...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_neither = df[(df['hate_speech'] != 0) & (df['neither'] != 0)]\n",
    "hate_neither.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a fair amount of disagreement, including some tweets that were marked by at least one person as being in every category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that Bayes error will be relatively high for this dataset. It would be hard to get a good estimate of that, but we can see how many tweets were unanimously agreed upon. This should give a decent baseline for a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_three = df[(df['hate_speech'] != 0) & (df['neither'] != 0) & (df['offensive_language'] != 0)]\n",
    "hate_offensive = df[(df['hate_speech'] != 0) & (df['offensive_language'] != 0)]\n",
    "offensive_neither = df[(df['neither'] != 0) & (df['offensive_language'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_multiple = pd.concat([hate_neither, hate_offensive, offensive_neither]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9506</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuck dat bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Citi field bitches http://t.co/gHxXmb3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8293</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like im nt beefing over a niggah smh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19107</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @brittanyaflores: you got niggas &amp;amp; I go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19918</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @laceeybugg: @hedge_brandon you're such a q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@CapoDaAssHole naw where can I see that hoe at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>that hoe aint there anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I had a date wit Irene nd that bitch stood me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@Flow935 jus wanted to let y&amp;#225;ll know hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15940</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @I_Be_kOoLz Food be good...except that rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @VillageBae: Don't block me because you thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16533</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @LeMarquand: &amp;#8252;&amp;#65039;Muslim group sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dawg ass hoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@J_Fritzy @vivaalakatyy @Lompartayy @brotherbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @worley_7: Enough with the mind fuck and pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I swear these hoes *aint got nothing on you * ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@MillerLite I don't follow you because everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@discordianslip If you say one disparaging wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22442</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This bitch is stupid. -.-; Anti Feminist: http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16836</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MikeDiggEm: Only ugly girls can fight. Pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "9506       3            1                   2        0      1   \n",
       "8717       3            1                   2        0      1   \n",
       "8293       3            1                   2        0      1   \n",
       "19107      3            1                   2        0      1   \n",
       "19918      3            1                   2        0      1   \n",
       "2839       6            0                   5        1      1   \n",
       "25003      3            0                   2        1      1   \n",
       "10690      3            1                   2        0      1   \n",
       "3266       6            4                   1        1      0   \n",
       "15940      3            0                   1        2      2   \n",
       "18396      3            1                   2        0      1   \n",
       "16533      3            0                   1        2      2   \n",
       "8903       3            0                   2        1      1   \n",
       "3679       3            0                   2        1      1   \n",
       "20788      6            1                   5        0      1   \n",
       "11213      3            0                   2        1      1   \n",
       "4245       3            2                   1        0      0   \n",
       "6022       3            0                   2        1      1   \n",
       "22442      3            1                   2        0      1   \n",
       "16836      3            1                   2        0      1   \n",
       "\n",
       "                                                   tweet  \n",
       "9506                                      Fuck dat bitch  \n",
       "8717             Citi field bitches http://t.co/gHxXmb3M  \n",
       "8293     Bitches be like im nt beefing over a niggah smh  \n",
       "19107  RT @brittanyaflores: you got niggas &amp; I go...  \n",
       "19918  RT @laceeybugg: @hedge_brandon you're such a q...  \n",
       "2839      @CapoDaAssHole naw where can I see that hoe at  \n",
       "25003                        that hoe aint there anymore  \n",
       "10690  I had a date wit Irene nd that bitch stood me ...  \n",
       "3266   @Flow935 jus wanted to let y&#225;ll know hope...  \n",
       "15940  RT @I_Be_kOoLz Food be good...except that rice...  \n",
       "18396  RT @VillageBae: Don't block me because you thi...  \n",
       "16533  RT @LeMarquand: &#8252;&#65039;Muslim group sl...  \n",
       "8903                                       Dawg ass hoes  \n",
       "3679   @J_Fritzy @vivaalakatyy @Lompartayy @brotherbi...  \n",
       "20788  RT @worley_7: Enough with the mind fuck and pa...  \n",
       "11213  I swear these hoes *aint got nothing on you * ...  \n",
       "4245   @MillerLite I don't follow you because everyth...  \n",
       "6022   @discordianslip If you say one disparaging wor...  \n",
       "22442  This bitch is stupid. -.-; Anti Feminist: http...  \n",
       "16836  RT @MikeDiggEm: Only ugly girls can fight. Pre...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_multiple.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many were unanimous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.5% of the samples were disputed. 70.5% were unanimous.\n"
     ]
    }
   ],
   "source": [
    "disputed = len(all_multiple)/len(df)\n",
    "print(\"{disputed:.1%} of the samples were disputed. {unanimous:.1%} were unanimous.\".format(disputed=disputed, unanimous=1-disputed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a good idea for how well we'll be able to do. Even a \"great\" classifier likely won't agree with the majority all of the time, as 29.5% of the samples had at least one dissenting opinion. This isn't quite Bayes error because it shows any disagreement, but it gives an idea that this won't be easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look in more detail at the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop pandas from truncating text\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4251     @Misplaced_Momma \\nHello dare momma. I show glad dat u follow me. U lbe screamin hot in dem pitchers. \\nYou eva b wit colored men?                        \n",
       "15438    RT @DymondMarie1: Shoutout to your main bitch !                                                                                                           \n",
       "16926    RT @MsKeeKee90s: Throw it up! Like a pizza! Get stirring in that pussy like a feature &#128514;&#128514;&#128514; @t_ndyy @PamiiBabesh                    \n",
       "4399     @Nien_Nunb what did you search? Gay redneck episode 1 play?                                                                                               \n",
       "4380     @Ncoleycole u still a mutt tho lol                                                                                                                        \n",
       "4998     @Taylor_Simonee you have your nips pierced too ?! &#127806;&#128064;&#127806;                                                                             \n",
       "17363    RT @QuinTheGreat: &#8220;@Lucki_Starr: When you accidentally say \"About a week ago\" http://t.co/JHBQhPUP2m&#8221; bitch u just wanted to show Ya ass smh  \n",
       "6795     @lybr3 and yes.THAT was very ghetto and condescending ESPECIALLY after her miserably failed crappy school lunch initiative. The Hypocrite                 \n",
       "9193     Endless but they really trash so none RT @Whoa_Kimbosabe: Men: how many positive(s) and possibles do y'all have on fri thru sun night?                    \n",
       "23694    You NEED an iPhone to use their stupid watch? Apple is just grabbing people ankles and shaking the money out of rubes pockets.                            \n",
       "11900    If yer gonna continue to be a contrarian bitch... go die then. I've no time for such trifling!                                                            \n",
       "2727     @Brandi_Nicolee get that degree first bitch                                                                                                               \n",
       "22597    This old bitch with floppy tits riding on the elevator with me is nerping so bad                                                                          \n",
       "2988     @Cuauhtli02 I couldn't find the regular one faggot                                                                                                        \n",
       "17629    RT @SenorSteez: Man, now these hoes know &#128514;&#128176;&#128182;&#128184; #TheJigIsUp http://t.co/8W9Ag3bx1a                                          \n",
       "10026    Headed straight to the top bitch.                                                                                                                         \n",
       "13372    My homeboy got a hoe number on house arrest ... i said that's good she won't ask to go anywhere                                                           \n",
       "2652     @Big_Jim777 bitch                                                                                                                                         \n",
       "1991     &#8220;@wizkhalifa: On the east coast there's colored hair everywhere. \\n\\nThis must be the sweetest wave ever.&#8221; @LayaFace                          \n",
       "18977    RT @anilkohli54: @mediacrooks so the ball did roll down the slope &amp; found a natural spot @madhutrehan defending brother &amp; the scumbag @sard&#8230;\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].sample(20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could clean this out by removing URLs and mentions, but we'll leave hashtags in. Looks like there are also emojis, like this &#128557;, that have been replace with text strings like like this `&#128557;`. We'll remove those too. We'll come up with regexes to remove them.\n",
    "\n",
    "It looks like there's also a ampersand issue. We'll fix that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "mention_regex = '@[\\w\\-]+'\n",
    "emoji_regex = '&#\\d*;'\n",
    "amp_regex = '&amp;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10906\n"
     ]
    }
   ],
   "source": [
    "text = df['clean']\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(url_regex, 'URLHERE', str(text))\n",
    "    text = re.sub(mention_regex, 'MENTIONHERE', str(text))\n",
    "    text = re.sub(emoji_regex, ' EMOJIHERE ', str(text))\n",
    "    text = re.sub(amp_regex, '&', str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['clean'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8207    I was just debating with myself whether I shou...\n",
       "7020                                 Try here Amazon.com.\n",
       "7290    They need to give them mandatory DNA tests and...\n",
       "9089    We all have unique abilities and knowledge , c...\n",
       "2643    Multiculturism is a Trojan Horse Multicultural...\n",
       "4911    hey, im from manhattan. its really rough havin...\n",
       "1670                                                 TF .\n",
       "5772    Cant say over the net what I do EVERY day for ...\n",
       "1085    I actually have a college degree , but choose ...\n",
       "8582    We have tons of links for materials and free d...\n",
       "2247    That news is something totally incomprihensible .\n",
       "9616    Main Entry : epis Â· tro Â· phe Pronunciation ...\n",
       "7958                  Does anybody else experience this ?\n",
       "5135    heil sisters and brothers lit see if this make...\n",
       "7631                  Oh, you 'd better believe they do .\n",
       "9603    Einstein said nothing can go faster than the s...\n",
       "1523    - `` Something about black '' and the old favo...\n",
       "1597          Yes but most are not even brown or tanned .\n",
       "6044                             Thanks, but I 'll pass .\n",
       "3820                              Absolutely ridiculous .\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'].sample(20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better (for hate speech). Now that we've cleaned it we'll save it and start generating some features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleanhate123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
